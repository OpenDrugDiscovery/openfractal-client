{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"openfractal-client","text":"<p>Important: if you are planning to work with the Openfractal instances, it is highly recommended to read the upstream documentation at https://molssi.github.io/QCFractal/overview/index.html.</p>"},{"location":"index.html#available-openfractal-instances","title":"Available Openfractal instances","text":"Name Comment API URL <code>openfractal-test</code> A test instance for learn how to use QCFractal. In case of reset, it will be communicated pro-actively. https://openfractal-test-pgzbs3yryq-uc.a.run.app <p>Oepnfractal Dashboard: https://openfractal-backend.vercel.app/</p>"},{"location":"index.html#user-accounts","title":"User accounts","text":"<p>To interact with any Openfractal instances, you must have a user account. Ask an administrator to create one for you. Here are the 5 roles you can have associated with your account:</p> <ul> <li>Admin</li> <li>Compute</li> <li>Read</li> <li>Submit</li> <li>Monitor</li> </ul>"},{"location":"index.html#usage-and-installation","title":"Usage and installation","text":"<p>The two main libraries to interact with the Openfractal instances are:</p> <ul> <li><code>qcportal</code>: a Python client for Openfractal (QCFractal instance).</li> <li><code>qcfractalcompute</code>: a Python client for Openfractal (QCFractal instance) that can launch a worker (also called a manager).</li> </ul> <p>For now the Python library of this repo <code>openfractal-client</code> does not contain any particular logic. The plan is to use it if we need custom logic related to openfractal moving forward.</p>"},{"location":"index.html#docker","title":"Docker","text":"<p>Public docker images are available at https://github.com/OpenDrugDiscovery/openfractal-client/pkgs/container/openfractal-client.</p> <pre><code>docker run --rm -ti ghcr.io/opendrugdiscovery/openfractal-client:main\n</code></pre>"},{"location":"index.html#using-mamba","title":"Using mamba","text":"<p>The QCFractal libraries ecosystem have not yet been released. It is actively being developed in the <code>next</code> branch at https://github.com/MolSSI/QCFractal/tree/next.</p> <p>For now here is a minimal Conda <code>env.yml</code> file you can use to perform the installation (this will be simplified in the future):</p> <pre><code>channels:\n- hadim/label/qcportal_next\n- conda-forge/label/libint_dev # for psi4\n- conda-forge\n\ndependencies:\n- python &gt;=3.9\n- pip\n\n# QCPortal deps\n- hadim/label/qcportal_next::qcportal\n- hadim/label/qcportal_next::qcfractalcompute\n\n# Compute managers\n- parsl\n- psi4 =1.8\n- openmm\n- openff-forcefields\n- openmmforcefields\n\n# Optional\n- datamol\n- openff-toolkit\n- zarr\n\n# Optional utilities\n- loguru\n- typer\n- python-dotenv\n</code></pre> <p>Put the above YAML file into <code>env.yml</code>. Then:</p> <pre><code>micromamba create -n openfractal -f env.yml\n</code></pre> <p>In the future, it will be as simple as <code>micromamba create -n openfractal openfractal-client</code>.</p>"},{"location":"license.html","title":"License","text":"<pre><code>Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright 2021 - 2023 datamol.io\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n</code></pre>"},{"location":"tutorials/01_submit_dataset.html","title":"Submit a Dataset","text":"<p>In this tutorial you'll learn how to submit a dataset to a QCFractal instance (also called backend or server).</p> In\u00a0[2]: Copied! <pre>import os\nimport dotenv\nimport random\n\nfrom tqdm.auto import tqdm\n\nimport datamol as dm\nimport pandas as pd\n\nfrom openff.toolkit import Molecule\n\nimport qcelemental as qcel\n\nfrom qcportal import PortalClient\nfrom qcportal.record_models import PriorityEnum\n\nfrom qcportal.singlepoint.dataset_models import SinglepointDatasetNewEntry\nfrom qcportal.singlepoint.record_models import QCSpecification\nfrom qcportal.singlepoint.record_models import SinglepointDriver\n\n_ = dotenv.load_dotenv(\"../../openfractal_test_secrets.env\")\n</pre> import os import dotenv import random  from tqdm.auto import tqdm  import datamol as dm import pandas as pd  from openff.toolkit import Molecule  import qcelemental as qcel  from qcportal import PortalClient from qcportal.record_models import PriorityEnum  from qcportal.singlepoint.dataset_models import SinglepointDatasetNewEntry from qcportal.singlepoint.record_models import QCSpecification from qcportal.singlepoint.record_models import SinglepointDriver  _ = dotenv.load_dotenv(\"../../openfractal_test_secrets.env\") <p>First we pull a random subset of <code>datamol.data.freesolv()</code>, create <code>openff.Molecule</code> objects from it and generate one conformer per molecule.</p> In\u00a0[2]: Copied! <pre>def get_toy_molecules(\n    n_molecules: int = 10,\n    progress: bool = True,\n    progress_leave: bool = False,\n):\n    # Get some data\n    data = dm.data.freesolv()\n    data = data.sample(n=n_molecules)\n\n    def _process(smiles):\n        # Convert to OFF mol\n        mol = Molecule.from_smiles(smiles)\n        assert mol is not None\n\n        # Generate a conformer\n        mol.generate_conformers(n_conformers=1)\n\n        return mol\n\n    # Generate conformers\n    data[\"mol\"] = dm.parallelized(\n        _process,\n        data[\"smiles\"],\n        progress=progress,\n        tqdm_kwargs=dict(leave=progress_leave),\n    )\n\n    data = data.reset_index(drop=True)\n    return data\n\n\ndata = get_toy_molecules(n_molecules=10)\n\ndata\n</pre> def get_toy_molecules(     n_molecules: int = 10,     progress: bool = True,     progress_leave: bool = False, ):     # Get some data     data = dm.data.freesolv()     data = data.sample(n=n_molecules)      def _process(smiles):         # Convert to OFF mol         mol = Molecule.from_smiles(smiles)         assert mol is not None          # Generate a conformer         mol.generate_conformers(n_conformers=1)          return mol      # Generate conformers     data[\"mol\"] = dm.parallelized(         _process,         data[\"smiles\"],         progress=progress,         tqdm_kwargs=dict(leave=progress_leave),     )      data = data.reset_index(drop=True)     return data   data = get_toy_molecules(n_molecules=10)  data <pre>  0%|          | 0/10 [00:00&lt;?, ?it/s]</pre> Out[2]: iupac smiles expt calc mol 0 pyridine c1ccncc1 -4.69 -3.508 Molecule with name '' and SMILES '[H][c]1[n][c... 1 ethyl propanoate CCC(=O)OCC -2.68 -3.221 Molecule with name '' and SMILES '[H][C]([H])(... 2 2-methylpyridine Cc1ccccn1 -4.63 -3.501 Molecule with name '' and SMILES '[H][c]1[n][c... 3 2,3-dichlorodibenzo-p-dioxin c1ccc2c(c1)Oc3cc(c(cc3O2)Cl)Cl -3.56 -3.590 Molecule with name '' and SMILES '[H][c]1[c]([... 4 1-acetoxyethyl acetate CC(OC(=O)C)OC(=O)C -4.97 -8.006 Molecule with name '' and SMILES '[H][C]([H])(... 5 2-methylhexane CCCCC(C)C 2.93 2.894 Molecule with name '' and SMILES '[H][C]([H])(... 6 simazine CCNc1nc(nc(n1)Cl)NCC -10.22 -10.914 Molecule with name '' and SMILES '[H][N]([c]1[... 7 triethylphosphate CCOP(=O)(OCC)OCC -7.50 -10.251 Molecule with name '' and SMILES '[H][C]([H])(... 8 methylcyclopentane CC1CCCC1 1.59 1.785 Molecule with name '' and SMILES '[H][C]([H])(... 9 hept-1-yne CCCCCC#C 0.60 0.639 Molecule with name '' and SMILES '[H][C]#[C][C... <p>The client object will allow to interact with any QCfractal instance.</p> In\u00a0[3]: Copied! <pre>client = PortalClient(\n    address=\"https://openfractal-test-pgzbs3yryq-uc.a.run.app\",\n    username=os.environ[\"OPENFRACTAL_USER_1_USERNAME\"],\n    password=os.environ[\"OPENFRACTAL_USER_1_PASSWORD\"],\n)\n\nclient\n</pre> client = PortalClient(     address=\"https://openfractal-test-pgzbs3yryq-uc.a.run.app\",     username=os.environ[\"OPENFRACTAL_USER_1_USERNAME\"],     password=os.environ[\"OPENFRACTAL_USER_1_PASSWORD\"], )  client Out[3]: PortalClient <ul> <li>Server:   \u00a0 openfractal-test</li> <li>Address:  \u00a0 https://openfractal-test-pgzbs3yryq-uc.a.run.app/</li> <li>Username: \u00a0 admin_default</li> </ul> <p>You can display some general informations about this instance:</p> In\u00a0[4]: Copied! <pre>client.server_info\n</pre> client.server_info Out[4]: <pre>{'name': 'openfractal-test',\n 'manager_heartbeat_frequency': 10,\n 'manager_heartbeat_max_missed': 5,\n 'version': '0.50b12.post16+gee831184',\n 'api_limits': {'get_records': 1000,\n  'add_records': 500,\n  'get_dataset_entries': 2000,\n  'get_molecules': 1000,\n  'add_molecules': 1000,\n  'get_managers': 1000,\n  'manager_tasks_claim': 200,\n  'manager_tasks_return': 10,\n  'get_server_stats': 25,\n  'get_access_logs': 1000,\n  'get_error_logs': 100,\n  'get_internal_jobs': 1000},\n 'client_version_lower_limit': '0.50b11',\n 'client_version_upper_limit': '1',\n 'manager_version_lower_limit': '0.50b11',\n 'manager_version_upper_limit': '1',\n 'motd': ''}</pre> In\u00a0[5]: Copied! <pre># Generate a random suffix for your dataset\ndataset_suffix = \"\".join(random.choices([str(i) for i in range(10)], k=10))\n\ndataset_name = f\"dataset_demo_{dataset_suffix}\"\n\ndataset_name\n</pre> # Generate a random suffix for your dataset dataset_suffix = \"\".join(random.choices([str(i) for i in range(10)], k=10))  dataset_name = f\"dataset_demo_{dataset_suffix}\"  dataset_name Out[5]: <pre>'dataset_demo_4321690179'</pre> In\u00a0[33]: Copied! <pre>kwargs = {}\nkwargs[\"dataset_type\"] = \"singlepoint\"\nkwargs[\"name\"] = dataset_name\nkwargs[\"description\"] = \"my great dataset!\"\n# the tag allows you to restrict this dataset to only specific managers\nkwargs[\"tags\"] = [\"demo_tutorial\"]  \nkwargs[\"group\"] = None\nkwargs[\"provenance\"] = {}\nkwargs[\"visibility\"] = True\nkwargs[\"default_tag\"] = \"demo_tutorial\"\nkwargs[\"default_priority\"] = PriorityEnum.normal\nkwargs[\"metadata\"] = {}\nkwargs[\"owner_group\"] = None\n\nds = client.add_dataset(**kwargs)\n\nds.dict()\n</pre> kwargs = {} kwargs[\"dataset_type\"] = \"singlepoint\" kwargs[\"name\"] = dataset_name kwargs[\"description\"] = \"my great dataset!\" # the tag allows you to restrict this dataset to only specific managers kwargs[\"tags\"] = [\"demo_tutorial\"]   kwargs[\"group\"] = None kwargs[\"provenance\"] = {} kwargs[\"visibility\"] = True kwargs[\"default_tag\"] = \"demo_tutorial\" kwargs[\"default_priority\"] = PriorityEnum.normal kwargs[\"metadata\"] = {} kwargs[\"owner_group\"] = None  ds = client.add_dataset(**kwargs)  ds.dict() Out[33]: <pre>{'id': 5,\n 'dataset_type': 'singlepoint',\n 'name': 'dataset_demo_4321690179',\n 'description': 'my great dataset!',\n 'tagline': '',\n 'tags': ['demo_tutorial'],\n 'group': 'default',\n 'visibility': True,\n 'provenance': {},\n 'default_tag': 'demo_tutorial',\n 'default_priority': &lt;PriorityEnum.normal: 1&gt;,\n 'owner_user': 'admin_default',\n 'owner_group': None,\n 'metadata': {},\n 'extras': {},\n 'entry_names_': [],\n 'specifications_': {},\n 'entries_': {},\n 'record_map_': {},\n 'contributed_values_': None,\n 'auto_fetch_missing': True}</pre> In\u00a0[34]: Copied! <pre>chunk_size = 5\nprogress = True\nprogress_leave = False\n\n\ndef _create_entry(i, row):\n    kwargs = {}\n    kwargs[\"name\"] = f\"mol_{i}\"\n    kwargs[\"molecule\"] = row[\"mol\"].to_qcschema()\n    kwargs[\"additional_keywords\"] = {}\n    kwargs[\"attributes\"] = row.drop(\"mol\").to_dict()\n    kwargs[\"comment\"] = None\n    return SinglepointDatasetNewEntry(**kwargs)\n\n\n# We build and send the entry by chunk in case of large dataset\nfor i in tqdm(range(0, len(data), chunk_size)):\n    # Get the rows\n    rows = data.iloc[i : i + chunk_size]\n\n    # Build the entries\n    entries = dm.parallelized(\n        _create_entry,\n        rows.iterrows(),\n        arg_type=\"args\",\n        total=len(rows),\n        progress=progress,\n        tqdm_kwargs=dict(leave=progress_leave),\n    )\n\n    # Send the entries to the server\n    insert_md = ds.add_entries(entries)\n    assert insert_md.success\n</pre> chunk_size = 5 progress = True progress_leave = False   def _create_entry(i, row):     kwargs = {}     kwargs[\"name\"] = f\"mol_{i}\"     kwargs[\"molecule\"] = row[\"mol\"].to_qcschema()     kwargs[\"additional_keywords\"] = {}     kwargs[\"attributes\"] = row.drop(\"mol\").to_dict()     kwargs[\"comment\"] = None     return SinglepointDatasetNewEntry(**kwargs)   # We build and send the entry by chunk in case of large dataset for i in tqdm(range(0, len(data), chunk_size)):     # Get the rows     rows = data.iloc[i : i + chunk_size]      # Build the entries     entries = dm.parallelized(         _create_entry,         rows.iterrows(),         arg_type=\"args\",         total=len(rows),         progress=progress,         tqdm_kwargs=dict(leave=progress_leave),     )      # Send the entries to the server     insert_md = ds.add_entries(entries)     assert insert_md.success <pre>  0%|          | 0/2 [00:00&lt;?, ?it/s]</pre> <pre>  0%|          | 0/5 [00:00&lt;?, ?it/s]</pre> <pre>  0%|          | 0/5 [00:00&lt;?, ?it/s]</pre> <p>You can check the newly submitted entries:</p> In\u00a0[35]: Copied! <pre>list(ds.iterate_entries())\n</pre> list(ds.iterate_entries()) Out[35]: <pre>[SinglepointDatasetEntry(name='mol_0', molecule=Molecule(name='C5H5N', formula='C5H5N', hash='a6c6d91'), additional_keywords={}, attributes={'calc': -3.508, 'expt': -4.69, 'iupac': 'pyridine', 'smiles': 'c1ccncc1'}, comment=None, local_results=None),\n SinglepointDatasetEntry(name='mol_1', molecule=Molecule(name='C5H10O2', formula='C5H10O2', hash='7d0fe6d'), additional_keywords={}, attributes={'calc': -3.221, 'expt': -2.68, 'iupac': 'ethyl propanoate', 'smiles': 'CCC(=O)OCC'}, comment=None, local_results=None),\n SinglepointDatasetEntry(name='mol_2', molecule=Molecule(name='C6H7N', formula='C6H7N', hash='7739509'), additional_keywords={}, attributes={'calc': -3.501, 'expt': -4.63, 'iupac': '2-methylpyridine', 'smiles': 'Cc1ccccn1'}, comment=None, local_results=None),\n SinglepointDatasetEntry(name='mol_3', molecule=Molecule(name='C12Cl2H6O2', formula='C12Cl2H6O2', hash='c785c43'), additional_keywords={}, attributes={'calc': -3.59, 'expt': -3.56, 'iupac': '2,3-dichlorodibenzo-p-dioxin', 'smiles': 'c1ccc2c(c1)Oc3cc(c(cc3O2)Cl)Cl'}, comment=None, local_results=None),\n SinglepointDatasetEntry(name='mol_4', molecule=Molecule(name='C6H10O4', formula='C6H10O4', hash='7de2fa5'), additional_keywords={}, attributes={'calc': -8.006, 'expt': -4.97, 'iupac': '1-acetoxyethyl acetate', 'smiles': 'CC(OC(=O)C)OC(=O)C'}, comment=None, local_results=None),\n SinglepointDatasetEntry(name='mol_5', molecule=Molecule(name='C7H16', formula='C7H16', hash='31ac45a'), additional_keywords={}, attributes={'calc': 2.894, 'expt': 2.93, 'iupac': '2-methylhexane', 'smiles': 'CCCCC(C)C'}, comment=None, local_results=None),\n SinglepointDatasetEntry(name='mol_6', molecule=Molecule(name='C7ClH12N5', formula='C7ClH12N5', hash='ab02e52'), additional_keywords={}, attributes={'calc': -10.914, 'expt': -10.22, 'iupac': 'simazine', 'smiles': 'CCNc1nc(nc(n1)Cl)NCC'}, comment=None, local_results=None),\n SinglepointDatasetEntry(name='mol_7', molecule=Molecule(name='C6H15O4P', formula='C6H15O4P', hash='3f198c7'), additional_keywords={}, attributes={'calc': -10.251, 'expt': -7.5, 'iupac': 'triethylphosphate', 'smiles': 'CCOP(=O)(OCC)OCC'}, comment=None, local_results=None),\n SinglepointDatasetEntry(name='mol_8', molecule=Molecule(name='C6H12', formula='C6H12', hash='bc0c2a1'), additional_keywords={}, attributes={'calc': 1.785, 'expt': 1.59, 'iupac': 'methylcyclopentane', 'smiles': 'CC1CCCC1'}, comment=None, local_results=None),\n SinglepointDatasetEntry(name='mol_9', molecule=Molecule(name='C7H12', formula='C7H12', hash='f9566b0'), additional_keywords={}, attributes={'calc': 0.639, 'expt': 0.6, 'iupac': 'hept-1-yne', 'smiles': 'CCCCCC#C'}, comment=None, local_results=None)]</pre> In\u00a0[36]: Copied! <pre>## PSI4 SCF properties\n## See https://psicode.org/psi4manual/master/oeprop.html#id2\nscf_properties = [\n    \"MBIS_CHARGES\",\n    \"WIBERG_LOWDIN_INDICES\",\n    \"MAYER_INDICES\",\n    \"LOWDIN_CHARGES\",\n    \"DIPOLE\",\n    \"QUADRUPOLE\",\n]\n\n## Build the protocols\n## One of: all, none or orbitals_and_eigenvalues\nprotocols = {\"wavefunction\": \"all\"}\n\n## Build the specification\nkwargs = {}\nkwargs[\"program\"] = \"psi4\"\nkwargs[\"driver\"] = SinglepointDriver.gradient\n# kwargs[\"method\"] = \"wb97m-d3bj\"\n# kwargs[\"basis\"] = \"def2-tzvppd\"\nkwargs[\"method\"] = \"hf\"\nkwargs[\"basis\"] = \"sto-3g\"\nkwargs[\"keywords\"] = {\"wcombine\": False, \"scf_properties\": scf_properties}\nkwargs[\"protocols\"] = protocols\n\nspecification = QCSpecification(**kwargs)\n\nspecification\n</pre> ## PSI4 SCF properties ## See https://psicode.org/psi4manual/master/oeprop.html#id2 scf_properties = [     \"MBIS_CHARGES\",     \"WIBERG_LOWDIN_INDICES\",     \"MAYER_INDICES\",     \"LOWDIN_CHARGES\",     \"DIPOLE\",     \"QUADRUPOLE\", ]  ## Build the protocols ## One of: all, none or orbitals_and_eigenvalues protocols = {\"wavefunction\": \"all\"}  ## Build the specification kwargs = {} kwargs[\"program\"] = \"psi4\" kwargs[\"driver\"] = SinglepointDriver.gradient # kwargs[\"method\"] = \"wb97m-d3bj\" # kwargs[\"basis\"] = \"def2-tzvppd\" kwargs[\"method\"] = \"hf\" kwargs[\"basis\"] = \"sto-3g\" kwargs[\"keywords\"] = {\"wcombine\": False, \"scf_properties\": scf_properties} kwargs[\"protocols\"] = protocols  specification = QCSpecification(**kwargs)  specification Out[36]: <pre>QCSpecification(program='psi4', driver=&lt;SinglepointDriver.gradient: 'gradient'&gt;, method='hf', basis='sto-3g', keywords={'wcombine': False, 'scf_properties': ['MBIS_CHARGES', 'WIBERG_LOWDIN_INDICES', 'MAYER_INDICES', 'LOWDIN_CHARGES', 'DIPOLE', 'QUADRUPOLE']}, protocols=AtomicResultProtocols(wavefunction=&lt;WavefunctionProtocolEnum.all: 'all'&gt;, stdout=True, error_correction=ErrorCorrectionProtocol(default_policy=True, policies=None), native_files=&lt;NativeFilesProtocolEnum.none: 'none'&gt;))</pre> <p>Now we associate this QM specification (protocol) to the dataset we created above to the server.</p> In\u00a0[37]: Copied! <pre>kwargs = {}\nkwargs[\"name\"] = \"simple_qm_calculation_demo\"\nkwargs[\"specification\"] = specification\nkwargs[\"description\"] = None\ninsert_md = ds.add_specification(**kwargs)\nassert insert_md\n</pre> kwargs = {} kwargs[\"name\"] = \"simple_qm_calculation_demo\" kwargs[\"specification\"] = specification kwargs[\"description\"] = None insert_md = ds.add_specification(**kwargs) assert insert_md In\u00a0[38]: Copied! <pre>list(ds.iterate_entries())\n</pre> list(ds.iterate_entries()) Out[38]: <pre>[SinglepointDatasetEntry(name='mol_0', molecule=Molecule(name='C5H5N', formula='C5H5N', hash='a6c6d91'), additional_keywords={}, attributes={'calc': -3.508, 'expt': -4.69, 'iupac': 'pyridine', 'smiles': 'c1ccncc1'}, comment=None, local_results=None),\n SinglepointDatasetEntry(name='mol_1', molecule=Molecule(name='C5H10O2', formula='C5H10O2', hash='7d0fe6d'), additional_keywords={}, attributes={'calc': -3.221, 'expt': -2.68, 'iupac': 'ethyl propanoate', 'smiles': 'CCC(=O)OCC'}, comment=None, local_results=None),\n SinglepointDatasetEntry(name='mol_2', molecule=Molecule(name='C6H7N', formula='C6H7N', hash='7739509'), additional_keywords={}, attributes={'calc': -3.501, 'expt': -4.63, 'iupac': '2-methylpyridine', 'smiles': 'Cc1ccccn1'}, comment=None, local_results=None),\n SinglepointDatasetEntry(name='mol_3', molecule=Molecule(name='C12Cl2H6O2', formula='C12Cl2H6O2', hash='c785c43'), additional_keywords={}, attributes={'calc': -3.59, 'expt': -3.56, 'iupac': '2,3-dichlorodibenzo-p-dioxin', 'smiles': 'c1ccc2c(c1)Oc3cc(c(cc3O2)Cl)Cl'}, comment=None, local_results=None),\n SinglepointDatasetEntry(name='mol_4', molecule=Molecule(name='C6H10O4', formula='C6H10O4', hash='7de2fa5'), additional_keywords={}, attributes={'calc': -8.006, 'expt': -4.97, 'iupac': '1-acetoxyethyl acetate', 'smiles': 'CC(OC(=O)C)OC(=O)C'}, comment=None, local_results=None),\n SinglepointDatasetEntry(name='mol_5', molecule=Molecule(name='C7H16', formula='C7H16', hash='31ac45a'), additional_keywords={}, attributes={'calc': 2.894, 'expt': 2.93, 'iupac': '2-methylhexane', 'smiles': 'CCCCC(C)C'}, comment=None, local_results=None),\n SinglepointDatasetEntry(name='mol_6', molecule=Molecule(name='C7ClH12N5', formula='C7ClH12N5', hash='ab02e52'), additional_keywords={}, attributes={'calc': -10.914, 'expt': -10.22, 'iupac': 'simazine', 'smiles': 'CCNc1nc(nc(n1)Cl)NCC'}, comment=None, local_results=None),\n SinglepointDatasetEntry(name='mol_7', molecule=Molecule(name='C6H15O4P', formula='C6H15O4P', hash='3f198c7'), additional_keywords={}, attributes={'calc': -10.251, 'expt': -7.5, 'iupac': 'triethylphosphate', 'smiles': 'CCOP(=O)(OCC)OCC'}, comment=None, local_results=None),\n SinglepointDatasetEntry(name='mol_8', molecule=Molecule(name='C6H12', formula='C6H12', hash='bc0c2a1'), additional_keywords={}, attributes={'calc': 1.785, 'expt': 1.59, 'iupac': 'methylcyclopentane', 'smiles': 'CC1CCCC1'}, comment=None, local_results=None),\n SinglepointDatasetEntry(name='mol_9', molecule=Molecule(name='C7H12', formula='C7H12', hash='f9566b0'), additional_keywords={}, attributes={'calc': 0.639, 'expt': 0.6, 'iupac': 'hept-1-yne', 'smiles': 'CCCCCC#C'}, comment=None, local_results=None)]</pre> In\u00a0[39]: Copied! <pre>ds.submit()\n</pre> ds.submit() <p>Check the submission worked.</p> In\u00a0[63]: Copied! <pre>print(ds.status_table())\n</pre> print(ds.status_table()) <pre>             specification    complete    running\n--------------------------  ----------  ---------\nsimple_qm_calculation_demo           4          6\n</pre> <p>Retrieve a dataset by its name.</p> In\u00a0[41]: Copied! <pre>ds = client.get_dataset(\"singlepoint\", dataset_name)\nds\n</pre> ds = client.get_dataset(\"singlepoint\", dataset_name) ds Out[41]: <pre>SinglepointDataset(id=5, dataset_type='singlepoint', name='dataset_demo_4321690179', description='my great dataset!', tagline='', tags=['demo_tutorial'], group='default', visibility=True, provenance={}, default_tag='demo_tutorial', default_priority=&lt;PriorityEnum.normal: 1&gt;, owner_user='admin_default', owner_group=None, metadata={}, extras={}, entry_names_=[], specifications_={}, entries_={}, record_map_={}, contributed_values_=None, auto_fetch_missing=True)</pre> <p>Print a table showing the status for a dataset.</p> In\u00a0[62]: Copied! <pre>print(ds.status_table())\n</pre> print(ds.status_table()) <pre>             specification    complete    running\n--------------------------  ----------  ---------\nsimple_qm_calculation_demo           2          8\n</pre> <p>Read the records (some might be completed but some might still be in progress or in failing state.</p> In\u00a0[57]: Copied! <pre>records_list = []\nfor r in tqdm(client.query_records(dataset_id=ds.id)):\n    # Access this object to fetch the potential errors when any\n    r.error\n    records_list.append(r.dict())\n\nrecords = pd.DataFrame(records_list)\nrecords = records.sort_values(\"id\")\nrecords = records.reset_index(drop=True)\n\nrecords\n</pre> records_list = [] for r in tqdm(client.query_records(dataset_id=ds.id)):     # Access this object to fetch the potential errors when any     r.error     records_list.append(r.dict())  records = pd.DataFrame(records_list) records = records.sort_values(\"id\") records = records.reset_index(drop=True)  records <pre>0it [00:00, ?it/s]</pre> Out[57]: id record_type is_service properties extras status manager_name created_on modified_on owner_user owner_group compute_history_ task_ service_ comments_ native_files_ specification molecule_id molecule_ wavefunction_ 0 15 singlepoint False {'pe energy': 0.0, 'scf dipole': [-0.000133218... {} RecordStatusEnum.complete manager_hadrien_local_1-gollum-ef38f2ac-b99a-4... 2023-06-23 00:01:50.894704 2023-06-23 00:03:46.557663 admin_default None [{'id': 15, 'record_id': 15, 'status': 'Record... None None None None {'program': 'psi4', 'driver': 'SinglepointDriv... 24 None None 1 52 singlepoint False {'pe energy': 0.0, 'scf dipole': [0.1806203110... {} RecordStatusEnum.complete manager_hadrien_local_1-gollum-ef38f2ac-b99a-4... 2023-06-23 00:01:50.894737 2023-06-23 00:06:23.031904 admin_default None [{'id': 52, 'record_id': 52, 'status': 'Record... None None None None {'program': 'psi4', 'driver': 'SinglepointDriv... 37 None None 2 269 singlepoint False None None RecordStatusEnum.running manager_hadrien_local_1-boromir-eb6f7b1c-7db1-... 2023-06-23 13:09:57.599294 2023-06-23 13:10:14.774596 admin_default None [] None None None None {'program': 'psi4', 'driver': 'SinglepointDriv... 131 None None 3 270 singlepoint False None None RecordStatusEnum.running manager_hadrien_local_1-boromir-eb6f7b1c-7db1-... 2023-06-23 13:09:57.599299 2023-06-23 13:10:14.774608 admin_default None [] None None None None {'program': 'psi4', 'driver': 'SinglepointDriv... 127 None None 4 271 singlepoint False None None RecordStatusEnum.running manager_hadrien_local_1-boromir-eb6f7b1c-7db1-... 2023-06-23 13:09:57.599300 2023-06-23 13:10:14.774614 admin_default None [] None None None None {'program': 'psi4', 'driver': 'SinglepointDriv... 130 None None 5 272 singlepoint False None None RecordStatusEnum.running manager_hadrien_local_1-boromir-eb6f7b1c-7db1-... 2023-06-23 13:09:57.599301 2023-06-23 13:10:14.774620 admin_default None [] None None None None {'program': 'psi4', 'driver': 'SinglepointDriv... 133 None None 6 273 singlepoint False None None RecordStatusEnum.running manager_hadrien_local_1-boromir-eb6f7b1c-7db1-... 2023-06-23 13:09:57.599302 2023-06-23 13:10:14.774626 admin_default None [] None None None None {'program': 'psi4', 'driver': 'SinglepointDriv... 129 None None 7 274 singlepoint False None None RecordStatusEnum.running manager_hadrien_local_1-boromir-eb6f7b1c-7db1-... 2023-06-23 13:09:57.599303 2023-06-23 13:10:14.774632 admin_default None [] None None None None {'program': 'psi4', 'driver': 'SinglepointDriv... 126 None None 8 275 singlepoint False None None RecordStatusEnum.running manager_hadrien_local_1-boromir-eb6f7b1c-7db1-... 2023-06-23 13:09:57.599303 2023-06-23 13:10:14.774638 admin_default None [] None None None None {'program': 'psi4', 'driver': 'SinglepointDriv... 132 None None 9 276 singlepoint False None None RecordStatusEnum.running manager_hadrien_local_1-boromir-eb6f7b1c-7db1-... 2023-06-23 13:09:57.599304 2023-06-23 13:10:14.774644 admin_default None [] None None None None {'program': 'psi4', 'driver': 'SinglepointDriv... 128 None None <p>Retrieve the ID of a given dataset.</p> In\u00a0[6]: Copied! <pre>client.list_datasets()\n</pre> client.list_datasets() Out[6]: <pre>[{'id': 1, 'dataset_type': 'singlepoint', 'dataset_name': 'dataset_1'},\n {'id': 3, 'dataset_type': 'singlepoint', 'dataset_name': 'dataset_2'}]</pre> In\u00a0[4]: Copied! <pre>dataset_id = client.get_dataset(\"singlepoint\", \"dataset_demo_4321690179\").id\ndataset_id\n</pre> dataset_id = client.get_dataset(\"singlepoint\", \"dataset_demo_4321690179\").id dataset_id Out[4]: <pre>5</pre> <p>Delete the dataset and its associated records.</p> <p>Warning: this step can't be reversed.</p> In\u00a0[5]: Copied! <pre>client.delete_dataset(dataset_id, delete_records=True)\n</pre> client.delete_dataset(dataset_id, delete_records=True) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorials/01_submit_dataset.html#prepare-the-dataset","title":"Prepare the dataset\u00b6","text":""},{"location":"tutorials/01_submit_dataset.html#initialize-the-portalclient","title":"Initialize the <code>PortalClient</code>\u00b6","text":""},{"location":"tutorials/01_submit_dataset.html#create-a-new-dataset-on-the-server","title":"Create a new dataset on the server\u00b6","text":""},{"location":"tutorials/01_submit_dataset.html#build-entries-from-the-dataset","title":"Build \"entries\" from the dataset\u00b6","text":"<p>An entry is a single data point object that hold a 3D atomistic system (also called a molecule). You can associate custom attributes to a given molecule.</p>"},{"location":"tutorials/01_submit_dataset.html#create-the-qm-specification","title":"Create the QM specification\u00b6","text":"<p>The QM specification defines a QM protocol that will be executed on a Dataset.</p> <p>Here we choose a cheap level of theory: <code>hf/sto-3g</code>.</p>"},{"location":"tutorials/01_submit_dataset.html#submit-the-computation","title":"Submit the computation\u00b6","text":"<p>Warning: once you have submitted a specification to a dataset, the compatible managers will start picking up jobs and perform the QM calculcations.</p>"},{"location":"tutorials/01_submit_dataset.html#monitoring","title":"Monitoring\u00b6","text":""},{"location":"tutorials/01_submit_dataset.html#delete-a-dataset-and-associated-records","title":"Delete a dataset and associated records\u00b6","text":"<p>Important: Before deleting the dataset you just created, you should check the other tutorials where you'll learn how to launch a manager than can perform the QM calculations submitted above!</p>"},{"location":"tutorials/02_execute_manager.html","title":"Settings to connect to the Fractal Server.","text":"<p>In this tutorial, you'll learn how to execute a QM manager and monitor it.</p> In\u00a0[1]: Copied! <pre>import os\nimport dotenv\n\nfrom tqdm.auto import tqdm\n\nimport pandas as pd\n\nfrom qcportal import PortalClient\n\n_ = dotenv.load_dotenv(\"../../openfractal_test_secrets.env\")\n</pre> import os import dotenv  from tqdm.auto import tqdm  import pandas as pd  from qcportal import PortalClient  _ = dotenv.load_dotenv(\"../../openfractal_test_secrets.env\") In\u00a0[2]: Copied! <pre>client = PortalClient(\n    address=\"https://openfractal-test-pgzbs3yryq-uc.a.run.app\",\n    username=os.environ[\"OPENFRACTAL_USER_5_USERNAME\"],\n    password=os.environ[\"OPENFRACTAL_USER_5_PASSWORD\"],\n)\n\nclient\n</pre> client = PortalClient(     address=\"https://openfractal-test-pgzbs3yryq-uc.a.run.app\",     username=os.environ[\"OPENFRACTAL_USER_5_USERNAME\"],     password=os.environ[\"OPENFRACTAL_USER_5_PASSWORD\"], )  client Out[2]: PortalClient <ul> <li>Server:   \u00a0 openfractal-test</li> <li>Address:  \u00a0 https://openfractal-test-pgzbs3yryq-uc.a.run.app/</li> <li>Username: \u00a0 monitor_default</li> </ul> In\u00a0[3]: Copied! <pre># Check connected compute managers (workers)\nmanagers = pd.DataFrame([m.dict() for m in client.query_managers()])\nmanagers\n</pre> # Check connected compute managers (workers) managers = pd.DataFrame([m.dict() for m in client.query_managers()]) managers Out[3]: id name cluster hostname username tags claimed successes failures rejected total_cpu_hours active_tasks active_cores active_memory status created_on modified_on manager_version programs log_ 0 4 manager_hadrien_local_1-boromir-eb6f7b1c-7db1-... manager_hadrien_local_1 boromir compute_default [demo_tutorial] 8 2 0 0 0.498862 0 96 96.0 ManagerStatusEnum.active 2023-06-23 13:10:14.627308 2023-06-23 13:11:15.473101 0.50b12.post16+gee831184 {'psi4': ['1.8'], 'rdkit': ['2023.3.2'], 'open... None 1 3 manager_hadrien_local_1-boromir-a0282050-ab6d-... manager_hadrien_local_1 boromir compute_default [demo] 6 6 0 0 0.052357 0 0 0.0 ManagerStatusEnum.inactive 2023-06-23 13:08:36.830162 2023-06-23 13:09:04.465528 0.50b12.post16+gee831184 {'openmm': ['8.0.0'], 'rdkit': ['2023.3.2'], '... None 2 2 manager_hadrien_local_1-gollum-226c03ff-f315-4... manager_hadrien_local_1 gollum compute_default [demo] 24 23 1 0 0.184606 0 0 0.0 ManagerStatusEnum.inactive 2023-06-23 00:16:20.420013 2023-06-23 00:17:00.632159 0.50b12.post16+gee831184 {'openmm': ['8.0.0'], 'rdkit': ['2023.3.1'], '... None 3 1 manager_hadrien_local_1-gollum-ef38f2ac-b99a-4... manager_hadrien_local_1 gollum compute_default [demo] 230 223 7 0 8.106712 0 0 0.0 ManagerStatusEnum.inactive 2023-06-23 00:02:43.885753 2023-06-23 00:15:11.932844 0.50b12.post16+gee831184 {'openmm': ['8.0.0'], 'psi4': ['1.8'], 'rdkit'... None In\u00a0[4]: Copied! <pre>dataset_name = \"dataset_demo_4321690179\"\n\nds = client.get_dataset(\"singlepoint\", dataset_name)\nds\n</pre> dataset_name = \"dataset_demo_4321690179\"  ds = client.get_dataset(\"singlepoint\", dataset_name) ds Out[4]: <pre>SinglepointDataset(id=5, dataset_type='singlepoint', name='dataset_demo_4321690179', description='my great dataset!', tagline='', tags=['demo_tutorial'], group='default', visibility=True, provenance={}, default_tag='demo_tutorial', default_priority=&lt;PriorityEnum.normal: 1&gt;, owner_user='admin_default', owner_group=None, metadata={}, extras={}, entry_names_=[], specifications_={}, entries_={}, record_map_={}, contributed_values_=None, auto_fetch_missing=True)</pre> <p>Refresh the below often.</p> In\u00a0[5]: Copied! <pre>print(ds.status_table())\n</pre> print(ds.status_table()) <pre>             specification    complete    running\n--------------------------  ----------  ---------\nsimple_qm_calculation_demo           4          6\n</pre> In\u00a0[6]: Copied! <pre>records_list = []\nfor r in tqdm(client.query_records(dataset_id=ds.id)):\n    # Access those objects to fetch them locally\n    r.error\n    r.wavefunction\n    records_list.append(r.dict())\n\nrecords = pd.DataFrame(records_list)\nrecords = records.sort_values(\"id\")\nrecords = records.reset_index(drop=True)\n\nrecords\n</pre> records_list = [] for r in tqdm(client.query_records(dataset_id=ds.id)):     # Access those objects to fetch them locally     r.error     r.wavefunction     records_list.append(r.dict())  records = pd.DataFrame(records_list) records = records.sort_values(\"id\") records = records.reset_index(drop=True)  records <pre>0it [00:00, ?it/s]</pre> Out[6]: id record_type is_service properties extras status manager_name created_on modified_on owner_user owner_group compute_history_ task_ service_ comments_ native_files_ specification molecule_id molecule_ wavefunction_ 0 15 singlepoint False {'pe energy': 0.0, 'scf dipole': [-0.000133218... {} RecordStatusEnum.complete manager_hadrien_local_1-gollum-ef38f2ac-b99a-4... 2023-06-23 00:01:50.894704 2023-06-23 00:03:46.557663 admin_default None [{'id': 15, 'record_id': 15, 'status': 'Record... None None None None {'program': 'psi4', 'driver': 'SinglepointDriv... 24 None {'compression_type': 'CompressionEnum.zstd', '... 1 52 singlepoint False {'pe energy': 0.0, 'scf dipole': [0.1806203110... {} RecordStatusEnum.complete manager_hadrien_local_1-gollum-ef38f2ac-b99a-4... 2023-06-23 00:01:50.894737 2023-06-23 00:06:23.031904 admin_default None [{'id': 52, 'record_id': 52, 'status': 'Record... None None None None {'program': 'psi4', 'driver': 'SinglepointDriv... 37 None {'compression_type': 'CompressionEnum.zstd', '... 2 269 singlepoint False {'pe energy': 0.0, 'scf dipole': [-0.012353689... {} RecordStatusEnum.complete manager_hadrien_local_1-boromir-eb6f7b1c-7db1-... 2023-06-23 13:09:57.599294 2023-06-23 13:11:15.156556 admin_default None [{'id': 261, 'record_id': 269, 'status': 'Reco... None None None None {'program': 'psi4', 'driver': 'SinglepointDriv... 131 None {'compression_type': 'CompressionEnum.zstd', '... 3 270 singlepoint False {'pe energy': 0.0, 'scf dipole': [-0.121177958... {} RecordStatusEnum.complete manager_hadrien_local_1-boromir-eb6f7b1c-7db1-... 2023-06-23 13:09:57.599299 2023-06-23 13:11:15.254221 admin_default None [{'id': 262, 'record_id': 270, 'status': 'Reco... None None None None {'program': 'psi4', 'driver': 'SinglepointDriv... 127 None {'compression_type': 'CompressionEnum.zstd', '... 4 271 singlepoint False None None RecordStatusEnum.running manager_hadrien_local_1-boromir-eb6f7b1c-7db1-... 2023-06-23 13:09:57.599300 2023-06-23 13:10:14.774614 admin_default None [] None None None None {'program': 'psi4', 'driver': 'SinglepointDriv... 130 None None 5 272 singlepoint False None None RecordStatusEnum.running manager_hadrien_local_1-boromir-eb6f7b1c-7db1-... 2023-06-23 13:09:57.599301 2023-06-23 13:10:14.774620 admin_default None [] None None None None {'program': 'psi4', 'driver': 'SinglepointDriv... 133 None None 6 273 singlepoint False None None RecordStatusEnum.running manager_hadrien_local_1-boromir-eb6f7b1c-7db1-... 2023-06-23 13:09:57.599302 2023-06-23 13:10:14.774626 admin_default None [] None None None None {'program': 'psi4', 'driver': 'SinglepointDriv... 129 None None 7 274 singlepoint False None None RecordStatusEnum.running manager_hadrien_local_1-boromir-eb6f7b1c-7db1-... 2023-06-23 13:09:57.599303 2023-06-23 13:10:14.774632 admin_default None [] None None None None {'program': 'psi4', 'driver': 'SinglepointDriv... 126 None None 8 275 singlepoint False None None RecordStatusEnum.running manager_hadrien_local_1-boromir-eb6f7b1c-7db1-... 2023-06-23 13:09:57.599303 2023-06-23 13:10:14.774638 admin_default None [] None None None None {'program': 'psi4', 'driver': 'SinglepointDriv... 132 None None 9 276 singlepoint False None None RecordStatusEnum.running manager_hadrien_local_1-boromir-eb6f7b1c-7db1-... 2023-06-23 13:09:57.599304 2023-06-23 13:10:14.774644 admin_default None [] None None None None {'program': 'psi4', 'driver': 'SinglepointDriv... 128 None None In\u00a0[7]: Copied! <pre>row = records.iloc[0]\n\nrow[\"properties\"].keys()\n</pre> row = records.iloc[0]  row[\"properties\"].keys() Out[7]: <pre>dict_keys(['pe energy', 'scf dipole', 'calcinfo_nmo', 'mbis charges', 'mbis dipoles', 'mayer indices', 'mayer_indices', 'return_energy', 'return_result', 'calcinfo_natom', 'calcinfo_nbeta', 'current dipole', 'current energy', 'lowdin charges', 'lowdin_charges', 'mbis octupoles', 'return_hessian', 'scf iterations', 'scf quadrupole', 'scf_iterations', 'calcinfo_nalpha', 'calcinfo_nbasis', 'hf total energy', 'hf virial ratio', 'return_gradient', 'current gradient', 'mbis quadrupoles', 'scf total energy', 'scf_total_energy', 'hf kinetic energy', 'hf total gradient', 'scf_dipole_moment', 'scf_total_hessian', 'scf total gradient', 'scf_total_gradient', 'dd solvation energy', 'hf potential energy', 'mbis valence widths', 'one-electron energy', 'two-electron energy', 'scf iteration energy', 'wiberg lowdin indices', 'wiberg_lowdin_indices', 'pcm polarization energy', 'scf_one_electron_energy', 'scf_two_electron_energy', 'current reference energy', 'nuclear repulsion energy', 'nuclear_repulsion_energy', 'mbis radial moments &lt;r^2&gt;', 'mbis radial moments &lt;r^3&gt;', 'mbis radial moments &lt;r^4&gt;'])</pre> In\u00a0[8]: Copied! <pre>row[\"wavefunction_\"].keys()\n</pre> row[\"wavefunction_\"].keys() Out[8]: <pre>dict_keys(['compression_type', 'data_url_', 'compressed_data_', 'decompressed_data_'])</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorials/02_execute_manager.html#launch-a-manager-local","title":"Launch a manager: local\u00b6","text":"<p>A manager is a QM worker that will perform any QM calculations provided by an Openfractal instance.</p> <p>You first need to create a YAML config file <code>manager_local.yml</code>:</p> <pre>base_folder: /tmp/qcf_compute\n\ncluster: manager_demo_local_1\n\nloglevel: INFO\nlogfile: null\n\nupdate_frequency: 30\n\n# Settings to connect to the Fractal Server.\nserver:\nfractal_uri: https://openfractal-test-pgzbs3yryq-uc.a.run.app\nusername: YOUR_USERNAME\npassword: YOUR_PASSWORD\nverify: false\n\n# How and where to detect the QM softwares.\nenvironments:\nuse_manager_environment: true\nconda: []\napptainer: []\n\nexecutors:\nlocal:\ntype: local\n\n# Common to all executors.\n\n# Tags are used to filter the tasks that will be sent to the manager.\nqueue_tags: [\"demo_tutorial\"]\nworker_init: []\nscratch_directory: null\nbind_address: null\ncores_per_worker: 16\nmemory_per_worker: 16 # GB\nextra_executor_options: {}\n\n# Specific options for the local executor.\nmax_workers: 4\n</pre> <p>Then you can start a manager with:</p> <pre>qcfractal-compute-manager --config manager_local.yml\n</pre>"},{"location":"tutorials/02_execute_manager.html#launch-a-manager-slurm","title":"Launch a manager: SLURM\u00b6","text":"<p>A manager is a QM worker that will perform any QM calculations provided by an Openfractal instance.</p> <p>You first need to create a YAML config file <code>manager_slurm.yml</code>:</p> <pre>base_folder: /tmp/qcf_compute\n\ncluster: manager_demo_slurm_1\n\nloglevel: INFO\nlogfile: null\n\nupdate_frequency: 30\n\n# Settings to connect to the Fractal Server.\nserver:\nfractal_uri: https://openfractal-test-pgzbs3yryq-uc.a.run.app\nusername: YOUR_USERNAME\npassword: YOUR_PASSWORD\nverify: false\n\n# How and where to detect the QM softwares.\nenvironments:\nuse_manager_environment: true\nconda: []\napptainer: []\n\nexecutors:\nslurm:\ntype: slurm\n\n# Common to all executors.\nqueue_tags: [\"demo_tutorial\"]\nworker_init: []\nscratch_directory: null\nbind_address: 127.0.0.1\ncores_per_worker: 16\nmemory_per_worker: 16 # GB\nextra_executor_options: {}\n\n# Specific options for the local executor.\nwalltime: \"1:00:00\"\nexclusive: false\npartition: null\naccount: null\nworkers_per_node: 7\nmax_nodes: 1\nscheduler_options: []\n</pre> <p>Then you can start a manager with:</p> <pre>qcfractal-compute-manager --config manager_slurm.yml\n</pre>"},{"location":"tutorials/02_execute_manager.html#monitor-the-managers","title":"Monitor the managers\u00b6","text":""},{"location":"tutorials/02_execute_manager.html#monitor-your-dataset","title":"Monitor your dataset\u00b6","text":""},{"location":"tutorials/03_export_dataset.html","title":"Export a Dataset","text":"<p>In this tutorial, you'll learn how to read and export records.</p> In\u00a0[2]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n\nfrom typing import cast\n\nimport os\nimport dotenv\n\nfrom tqdm.auto import tqdm\n\nimport datamol as dm\nimport pandas as pd\n\nimport zarr\n\nfrom openff.toolkit import Molecule\nimport qcelemental as qcel\nfrom qcportal import PortalClient\n\n_ = dotenv.load_dotenv(\"../../openfractal_test_secrets.env\")\n</pre> %load_ext autoreload %autoreload 2  from typing import cast  import os import dotenv  from tqdm.auto import tqdm  import datamol as dm import pandas as pd  import zarr  from openff.toolkit import Molecule import qcelemental as qcel from qcportal import PortalClient  _ = dotenv.load_dotenv(\"../../openfractal_test_secrets.env\") In\u00a0[4]: Copied! <pre>client = PortalClient(\n    address=\"https://openfractal-test-pgzbs3yryq-uc.a.run.app\",\n    username=os.environ[\"OPENFRACTAL_USER_3_USERNAME\"],\n    password=os.environ[\"OPENFRACTAL_USER_3_PASSWORD\"],\n)\n\nclient\n</pre> client = PortalClient(     address=\"https://openfractal-test-pgzbs3yryq-uc.a.run.app\",     username=os.environ[\"OPENFRACTAL_USER_3_USERNAME\"],     password=os.environ[\"OPENFRACTAL_USER_3_PASSWORD\"], )  client Out[4]: PortalClient <ul> <li>Server:   \u00a0 openfractal-test</li> <li>Address:  \u00a0 https://openfractal-test-pgzbs3yryq-uc.a.run.app/</li> <li>Username: \u00a0 read_default</li> </ul> <p>Let's list the available dataset.</p> In\u00a0[5]: Copied! <pre>client.list_datasets()\n</pre> client.list_datasets() Out[5]: <pre>[{'id': 4,\n  'dataset_type': 'singlepoint',\n  'dataset_name': 'dataset_demo_5077749542'}]</pre> In\u00a0[6]: Copied! <pre>dataset_name = \"dataset_demo_4321690179\"\n\nds = client.get_dataset(\"singlepoint\", dataset_name)\nds\n</pre> dataset_name = \"dataset_demo_4321690179\"  ds = client.get_dataset(\"singlepoint\", dataset_name) ds Out[6]: <pre>SinglepointDataset(id=4, dataset_type='singlepoint', name='dataset_demo_5077749542', description='my great dataset!', tagline='', tags=['demo_local'], group='default', visibility=True, provenance={}, default_tag='demo_local', default_priority=&lt;PriorityEnum.normal: 1&gt;, owner_user='admin_default', owner_group=None, metadata={}, extras={}, entry_names_=[], specifications_={}, entries_={}, record_map_={}, contributed_values_=None, auto_fetch_missing=True)</pre> <p>Refresh the below often.</p> In\u00a0[7]: Copied! <pre>print(ds.status_table())\n</pre> print(ds.status_table()) <pre>             specification    complete    error\n--------------------------  ----------  -------\nsimple_qm_calculation_demo           8        2\n</pre> In\u00a0[8]: Copied! <pre>records_list = []\nfor r in tqdm(client.query_records(dataset_id=ds.id)):\n    # Access those objects to fetch them locally\n    r.error\n    r.wavefunction\n    records_list.append(r.dict())\n\nrecords = pd.DataFrame(records_list)\nrecords = records.sort_values(\"id\")\nrecords = records.reset_index(drop=True)\n\nrecords\n</pre> records_list = [] for r in tqdm(client.query_records(dataset_id=ds.id)):     # Access those objects to fetch them locally     r.error     r.wavefunction     records_list.append(r.dict())  records = pd.DataFrame(records_list) records = records.sort_values(\"id\") records = records.reset_index(drop=True)  records <pre>0it [00:00, ?it/s]</pre> Out[8]: id record_type is_service properties extras status manager_name created_on modified_on owner_user owner_group compute_history_ task_ service_ comments_ native_files_ specification molecule_id molecule_ wavefunction_ 0 11 singlepoint False {'pe energy': 0.0, 'scf dipole': [0.0335809823... {} RecordStatusEnum.complete manager_demo_local-boromir-86f6c0ce-e825-41f3-... 2023-06-12 20:22:35.161042 2023-06-12 20:23:29.625597 admin_default None [{'id': 1, 'record_id': 11, 'status': 'RecordS... None None None None {'program': 'psi4', 'driver': 'SinglepointDriv... 28 None {'compression_type': 'CompressionEnum.zstd', '... 1 12 singlepoint False {'pe energy': 0.0, 'scf dipole': [-0.191476353... {} RecordStatusEnum.complete manager_demo_local-boromir-86f6c0ce-e825-41f3-... 2023-06-12 20:22:35.161047 2023-06-12 20:23:29.788551 admin_default None [{'id': 2, 'record_id': 12, 'status': 'RecordS... None None None None {'program': 'psi4', 'driver': 'SinglepointDriv... 21 None {'compression_type': 'CompressionEnum.zstd', '... 2 13 singlepoint False {'pe energy': 0.0, 'scf dipole': [0.0032987900... {} RecordStatusEnum.complete manager_demo_local-boromir-86f6c0ce-e825-41f3-... 2023-06-12 20:22:35.161048 2023-06-12 20:23:29.856461 admin_default None [{'id': 3, 'record_id': 13, 'status': 'RecordS... None None None None {'program': 'psi4', 'driver': 'SinglepointDriv... 24 None {'compression_type': 'CompressionEnum.zstd', '... 3 14 singlepoint False {'pe energy': 0.0, 'scf dipole': [-0.356400390... {} RecordStatusEnum.complete manager_demo_local-boromir-86f6c0ce-e825-41f3-... 2023-06-12 20:22:35.161049 2023-06-12 20:24:00.283171 admin_default None [{'id': 4, 'record_id': 14, 'status': 'RecordS... None None None None {'program': 'psi4', 'driver': 'SinglepointDriv... 20 None {'compression_type': 'CompressionEnum.zstd', '... 4 15 singlepoint False {'pe energy': 0.0, 'scf dipole': [0.0085374704... {} RecordStatusEnum.complete manager_demo_local-boromir-86f6c0ce-e825-41f3-... 2023-06-12 20:22:35.161050 2023-06-12 20:24:00.373625 admin_default None [{'id': 5, 'record_id': 15, 'status': 'RecordS... None None None None {'program': 'psi4', 'driver': 'SinglepointDriv... 27 None {'compression_type': 'CompressionEnum.zstd', '... 5 16 singlepoint False {'pe energy': 0.0, 'scf dipole': [0.8039027310... {} RecordStatusEnum.complete manager_demo_local-boromir-86f6c0ce-e825-41f3-... 2023-06-12 20:22:35.161051 2023-06-12 20:24:30.943935 admin_default None [{'id': 6, 'record_id': 16, 'status': 'RecordS... None None None None {'program': 'psi4', 'driver': 'SinglepointDriv... 23 None {'compression_type': 'CompressionEnum.zstd', '... 6 17 singlepoint False None None RecordStatusEnum.error manager_demo_local-boromir-86f6c0ce-e825-41f3-... 2023-06-12 20:22:35.161052 2023-06-12 20:24:31.153263 admin_default None [{'id': 7, 'record_id': 17, 'status': 'RecordS... None None None None {'program': 'psi4', 'driver': 'SinglepointDriv... 26 None None 7 18 singlepoint False {'pe energy': 0.0, 'scf dipole': [-0.453720071... {} RecordStatusEnum.complete manager_demo_local-boromir-86f6c0ce-e825-41f3-... 2023-06-12 20:22:35.161053 2023-06-12 20:25:01.445537 admin_default None [{'id': 8, 'record_id': 18, 'status': 'RecordS... None None None None {'program': 'psi4', 'driver': 'SinglepointDriv... 29 None {'compression_type': 'CompressionEnum.zstd', '... 8 19 singlepoint False {'pe energy': 0.0, 'scf dipole': [0.0792046587... {} RecordStatusEnum.complete manager_demo_local-boromir-86f6c0ce-e825-41f3-... 2023-06-12 20:22:35.161054 2023-06-12 20:25:01.517410 admin_default None [{'id': 9, 'record_id': 19, 'status': 'RecordS... None None None None {'program': 'psi4', 'driver': 'SinglepointDriv... 25 None {'compression_type': 'CompressionEnum.zstd', '... 9 20 singlepoint False None None RecordStatusEnum.error manager_demo_local-boromir-86f6c0ce-e825-41f3-... 2023-06-12 20:22:35.161054 2023-06-12 20:25:01.602811 admin_default None [{'id': 10, 'record_id': 20, 'status': 'Record... None None None None {'program': 'psi4', 'driver': 'SinglepointDriv... 22 None None In\u00a0[9]: Copied! <pre>def export_dataset_to_zarr(\n    client: PortalClient,\n    dataset_name: str,\n    dataset_type: str,\n    output_file: str,\n    chunksize: int = 1_000,\n    progress: bool = True,\n    progress_leave: bool = False,\n):\n    # This could be easily parallelized if we want to.\n    # Parallelization will not work if using ZIP.\n\n    # Get the dataset\n    ds = client.get_dataset(dataset_type=dataset_type, dataset_name=dataset_name)\n\n    root = zarr.open(output_file, mode=\"w\")\n    root = cast(zarr.Group, root)\n    molecules_group = root.create_group(\"/molecules\")\n\n    for i in tqdm(\n        range(0, len(ds.entry_names), chunksize),\n        disable=not progress,\n        leave=progress_leave,\n    ):\n        # Pull completed records for those entry names\n        chunk_entry_names = ds.entry_names[i : i + chunksize]\n        records = ds.iterate_records(\n            entry_names=chunk_entry_names, status=\"complete\", force_refetch=True\n        )\n\n        for entry_name, specification_name, record in records:\n            # Fetch molecule\n            record.molecule\n            # Fetch wavefunction\n            record.wavefunction\n            # Fetch compute_history\n            record.compute_history_  # consider not fetching it\n\n            # Get dict\n            record_dict = record.dict()\n\n            # Get infos about the molecule (3D system)\n            mol = record_dict[\"molecule_\"]\n\n            smiles = mol[\"extras\"][\"canonical_isomeric_explicit_hydrogen_mapped_smiles\"]\n            molecule_hash = mol[\"identifiers\"][\"molecule_hash\"]\n            conformations = mol[\"geometry\"]\n\n            # Get a group for that molecule\n            if molecule_hash in molecules_group:\n                molecule_group = molecules_group[molecule_hash]\n            else:\n                molecule_group = molecules_group.create_group(molecule_hash)\n\n            # Save infos about the molecule\n            molecule_group.attrs[\"smiles\"] = smiles\n            molecule_group.attrs[\"molecule_hash\"] = molecule_hash\n            molecule_group[\"conformations\"] = conformations\n\n            # Get group for all the specifications for that molecule\n            if \"specifications\" in molecule_group:\n                specifications_group = molecule_group[\"specifications\"]\n            else:\n                specifications_group = molecule_group.create_group(\"specifications\")\n\n            # Get a group for that specification\n            if specification_name in specifications_group:\n                raise ValueError(\n                    f\"The specification '{specification_name}' already exists.\"\n                )\n            else:\n                specification_group = specifications_group.create_group(\n                    specification_name\n                )\n\n            specification_group.attrs[\"entry_name\"] = entry_name\n            specification_group.attrs[\"specification_name\"] = specification_name\n\n            # Save the infos of the specification as attributes\n            specification_group.attrs[\"id\"] = record_dict[\"id\"]\n            specification_group.attrs[\"record_type\"] = record_dict[\"record_type\"]\n            specification_group.attrs[\"is_service\"] = record_dict[\"is_service\"]\n            specification_group.attrs[\"extras\"] = record_dict[\"extras\"]\n            specification_group.attrs[\"status\"] = record_dict[\"status\"]\n            specification_group.attrs[\"manager_name\"] = record_dict[\"manager_name\"]\n            specification_group.attrs[\"created_on\"] = record_dict[\n                \"created_on\"\n            ].isoformat()\n            specification_group.attrs[\"modified_on\"] = record_dict[\n                \"modified_on\"\n            ].isoformat()\n            specification_group.attrs[\"owner_user\"] = record_dict[\"owner_user\"]\n            specification_group.attrs[\"owner_group\"] = record_dict[\"owner_group\"]\n            specification_group.attrs[\"compute_history_\"] = record_dict[\n                \"compute_history_\"\n            ]\n            specification_group.attrs[\"task_\"] = record_dict[\"task_\"]\n            specification_group.attrs[\"service_\"] = record_dict[\"service_\"]\n            specification_group.attrs[\"comments_\"] = record_dict[\"comments_\"]\n            specification_group.attrs[\"native_files_\"] = record_dict[\"native_files_\"]\n            specification_group.attrs[\"molecule_id\"] = record_dict[\"molecule_id\"]\n\n            # For now we save the QM properties and the wavefunction as attributes as well.\n            # This is obviously NOT IDEAL.\n            specification_group.attrs[\"wavefunction_\"] = record_dict[\"specification\"]\n            specification_group.attrs[\"properties\"] = record_dict[\"properties\"]\n\n    # Cleanup (only needed when zip file)\n    root.store.close()\n\n    return root\n</pre> def export_dataset_to_zarr(     client: PortalClient,     dataset_name: str,     dataset_type: str,     output_file: str,     chunksize: int = 1_000,     progress: bool = True,     progress_leave: bool = False, ):     # This could be easily parallelized if we want to.     # Parallelization will not work if using ZIP.      # Get the dataset     ds = client.get_dataset(dataset_type=dataset_type, dataset_name=dataset_name)      root = zarr.open(output_file, mode=\"w\")     root = cast(zarr.Group, root)     molecules_group = root.create_group(\"/molecules\")      for i in tqdm(         range(0, len(ds.entry_names), chunksize),         disable=not progress,         leave=progress_leave,     ):         # Pull completed records for those entry names         chunk_entry_names = ds.entry_names[i : i + chunksize]         records = ds.iterate_records(             entry_names=chunk_entry_names, status=\"complete\", force_refetch=True         )          for entry_name, specification_name, record in records:             # Fetch molecule             record.molecule             # Fetch wavefunction             record.wavefunction             # Fetch compute_history             record.compute_history_  # consider not fetching it              # Get dict             record_dict = record.dict()              # Get infos about the molecule (3D system)             mol = record_dict[\"molecule_\"]              smiles = mol[\"extras\"][\"canonical_isomeric_explicit_hydrogen_mapped_smiles\"]             molecule_hash = mol[\"identifiers\"][\"molecule_hash\"]             conformations = mol[\"geometry\"]              # Get a group for that molecule             if molecule_hash in molecules_group:                 molecule_group = molecules_group[molecule_hash]             else:                 molecule_group = molecules_group.create_group(molecule_hash)              # Save infos about the molecule             molecule_group.attrs[\"smiles\"] = smiles             molecule_group.attrs[\"molecule_hash\"] = molecule_hash             molecule_group[\"conformations\"] = conformations              # Get group for all the specifications for that molecule             if \"specifications\" in molecule_group:                 specifications_group = molecule_group[\"specifications\"]             else:                 specifications_group = molecule_group.create_group(\"specifications\")              # Get a group for that specification             if specification_name in specifications_group:                 raise ValueError(                     f\"The specification '{specification_name}' already exists.\"                 )             else:                 specification_group = specifications_group.create_group(                     specification_name                 )              specification_group.attrs[\"entry_name\"] = entry_name             specification_group.attrs[\"specification_name\"] = specification_name              # Save the infos of the specification as attributes             specification_group.attrs[\"id\"] = record_dict[\"id\"]             specification_group.attrs[\"record_type\"] = record_dict[\"record_type\"]             specification_group.attrs[\"is_service\"] = record_dict[\"is_service\"]             specification_group.attrs[\"extras\"] = record_dict[\"extras\"]             specification_group.attrs[\"status\"] = record_dict[\"status\"]             specification_group.attrs[\"manager_name\"] = record_dict[\"manager_name\"]             specification_group.attrs[\"created_on\"] = record_dict[                 \"created_on\"             ].isoformat()             specification_group.attrs[\"modified_on\"] = record_dict[                 \"modified_on\"             ].isoformat()             specification_group.attrs[\"owner_user\"] = record_dict[\"owner_user\"]             specification_group.attrs[\"owner_group\"] = record_dict[\"owner_group\"]             specification_group.attrs[\"compute_history_\"] = record_dict[                 \"compute_history_\"             ]             specification_group.attrs[\"task_\"] = record_dict[\"task_\"]             specification_group.attrs[\"service_\"] = record_dict[\"service_\"]             specification_group.attrs[\"comments_\"] = record_dict[\"comments_\"]             specification_group.attrs[\"native_files_\"] = record_dict[\"native_files_\"]             specification_group.attrs[\"molecule_id\"] = record_dict[\"molecule_id\"]              # For now we save the QM properties and the wavefunction as attributes as well.             # This is obviously NOT IDEAL.             specification_group.attrs[\"wavefunction_\"] = record_dict[\"specification\"]             specification_group.attrs[\"properties\"] = record_dict[\"properties\"]      # Cleanup (only needed when zip file)     root.store.close()      return root In\u00a0[10]: Copied! <pre>dataset_name = \"dataset_demo_5077749542\"\n\nroot = export_dataset_to_zarr(\n    client=client,\n    dataset_name=dataset_name,\n    dataset_type=\"singlepoint\",\n    output_file=\"/home/hadim/test_openfractal.zarr\",\n    chunksize=1_000,\n)\n</pre> dataset_name = \"dataset_demo_5077749542\"  root = export_dataset_to_zarr(     client=client,     dataset_name=dataset_name,     dataset_type=\"singlepoint\",     output_file=\"/home/hadim/test_openfractal.zarr\",     chunksize=1_000, ) <pre>  0%|          | 0/1 [00:00&lt;?, ?it/s]</pre> In\u00a0[86]: Copied! <pre>\n</pre>"},{"location":"tutorials/03_export_dataset.html#initialize-the-client-and-list-the-datasets","title":"Initialize the client and list the datasets\u00b6","text":""},{"location":"tutorials/03_export_dataset.html#load-a-dataset-given-its-name-and-fetch-its-records","title":"Load a dataset given its name and fetch its records\u00b6","text":""},{"location":"tutorials/03_export_dataset.html#end-to-end-export-to-zarr","title":"End-to-end export to Zarr\u00b6","text":"<p>The below function is opiniated en-to-end export pipeline. It's very opiniated and probably not optimal since many of the outputs are not stored as array.</p> <p>Use it as a guide to export and store only the relevant informations for your usecase.</p>"}]}